{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db0c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "읽은 df_words 컬럼명: ['month', 'count', 'rank', 'word', 'frequency']\n",
      "\n",
      "월별 등락률 예시:\n",
      "  year_month    first     last  pct_change category\n",
      "0    2020-01  9352.89  7200.85   -0.230094     down\n",
      "1    2020-02  8523.61  9384.61    0.101014       up\n",
      "2    2020-03  6410.44  8531.88    0.330935       up\n",
      "3    2020-04  8620.00  6642.92   -0.229360     down\n",
      "4    2020-05  9448.27  8826.96   -0.065759  neutral\n",
      "\n",
      "=== 카테고리별 상위 5개 단어 (빈도 합계 기준) ===\n",
      "category word  frequency\n",
      "    down   코인       2519\n",
      "    down   비트       2168\n",
      "    down   버그       1264\n",
      "    down   사람       1221\n",
      "    down   따리        787\n",
      " neutral   코인       1411\n",
      " neutral   비트       1168\n",
      " neutral   사람        783\n",
      " neutral   정신        705\n",
      " neutral   존귀        438\n",
      "      up   코인       1487\n",
      "      up   비트       1292\n",
      "      up  하나님       1211\n",
      "      up   사람        855\n",
      "      up   정신        513\n",
      "\n",
      "=== pct_change와 양(+) 상관 상위 5개 단어 ===\n",
      " 단어   상관계수\n",
      " 팬티 0.4058\n",
      " 누나 0.3510\n",
      " 승현 0.3510\n",
      " 치기 0.3510\n",
      "박치기 0.3510\n",
      "\n",
      "=== pct_change와 음(-) 상관 상위 5개 단어 ===\n",
      "  단어    상관계수\n",
      "  알트 -0.2647\n",
      "  리퍼 -0.2699\n",
      "  리플 -0.2832\n",
      "  입금 -0.2956\n",
      "비트코인 -0.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmj\\AppData\\Local\\Temp\\ipykernel_16720\\3626450370.py:79: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(['category','word'])['frequency']\n",
      "C:\\Users\\kmj\\AppData\\Local\\Temp\\ipykernel_16720\\3626450370.py:86: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby('category')\n",
      "c:\\Users\\kmj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CNN 모델 학습 시작 ===\n",
      "Epoch 1/20\n",
      "6/6 - 2s - 265ms/step - accuracy: 0.2667 - loss: 4.8831 - val_accuracy: 0.1667 - val_loss: 4.5767\n",
      "Epoch 2/20\n",
      "6/6 - 0s - 19ms/step - accuracy: 0.2667 - loss: 2.0589 - val_accuracy: 0.5000 - val_loss: 1.5435\n",
      "Epoch 3/20\n",
      "6/6 - 0s - 18ms/step - accuracy: 0.2444 - loss: 1.7782 - val_accuracy: 0.1667 - val_loss: 1.6613\n",
      "Epoch 4/20\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.2222 - loss: 1.7759 - val_accuracy: 0.5000 - val_loss: 0.9612\n",
      "Epoch 5/20\n",
      "6/6 - 0s - 19ms/step - accuracy: 0.3111 - loss: 1.3591 - val_accuracy: 0.1667 - val_loss: 3.6327\n",
      "Epoch 6/20\n",
      "6/6 - 0s - 19ms/step - accuracy: 0.3778 - loss: 1.7670 - val_accuracy: 0.3333 - val_loss: 1.4312\n",
      "Epoch 7/20\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.3111 - loss: 1.2275 - val_accuracy: 0.5000 - val_loss: 1.0112\n",
      "\n",
      "=== 테스트 세트 평가 ===\n",
      "Loss: 1.6441, Accuracy: 0.3077\n",
      "\n",
      "=== 모델링 기법 설명 ===\n",
      "이 스크립트에서는 '월별 단어 빈도 벡터'를 1차원 시계열처럼 보고,\n",
      "Conv1D(1D Convolutional Neural Network) 레이어를 통해 특징을 추출한 뒤\n",
      "GlobalMaxPooling1D → Dense → Softmax 구조로 'down', 'neutral', 'up' 세 클래스를 예측합니다.\n",
      "즉, 단어 빈도 패턴을 CNN이 학습하여 BTC 월별 등락 카테고리를 분류하는 모델링 방식입니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================\n",
    "# 설정: 파일 경로 지정\n",
    "# ============================\n",
    "WORD_FILE  = '../community/monthly_word_alt.csv'               # 예: 'monthly_word_alt.csv'\n",
    "# WORD_FILE  = './community/monthly_word_Chart.csv'               # 예: 'monthly_word_alt.csv'\n",
    "# WORD_FILE  = './community/monthly_word_electronicmoney.csv'               # 예: 'monthly_word_alt.csv'\n",
    "CHART_FILE = '../chart/BINANCE_BTCUSDT_daily_UTC.csv'\n",
    "\n",
    "# ============================\n",
    "# 1) 월별 단어 빈도 데이터 로드\n",
    "# ============================\n",
    "# 파일이 “콤마(,) 구분된 CSV”이므로 sep=',' 사용\n",
    "df_words = pd.read_csv(\n",
    "    WORD_FILE,\n",
    "    sep=',',\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "# 컬럼: ['month', 'count', 'rankw', 'word', 'frequency']\n",
    "print(\"읽은 df_words 컬럼명:\", df_words.columns.tolist())\n",
    "\n",
    "# ============================\n",
    "# 2) df_chart(일별 BTCUSDT 차트) 데이터 로드\n",
    "# ============================\n",
    "df_chart = pd.read_csv(\n",
    "    CHART_FILE,\n",
    "    parse_dates=['date']\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 3) 데이터 전처리: 'year_month' 생성 & 월별 등락률 계산\n",
    "# ============================\n",
    "# 3-1) df_words: 'month' 열이 이미 'YYYY-MM' 형식이므로 바로 활용\n",
    "df_words['year_month'] = df_words['month']  # 예: \"2020-01\", \"2020-02\", …\n",
    "\n",
    "# 3-2) df_chart: 'date' → 'year_month'(period) → 시가/종가 집계 → 등락률 계산\n",
    "df_chart['year_month'] = df_chart['date'].dt.to_period('M')\n",
    "monthly_prices = (\n",
    "    df_chart\n",
    "    .groupby('year_month')['close']\n",
    "    .agg(first='first', last='last')\n",
    "    .reset_index()\n",
    ")\n",
    "monthly_prices['pct_change'] = (\n",
    "    monthly_prices['last'] - monthly_prices['first']\n",
    ") / monthly_prices['first']\n",
    "monthly_prices['year_month'] = monthly_prices['year_month'].dt.strftime('%Y-%m')\n",
    "\n",
    "# 3-3) 등락률 기준으로 카테고리 분류: down(≤-10%), neutral(–10%~+10%), up(≥+10%)\n",
    "monthly_prices['category'] = pd.cut(\n",
    "    monthly_prices['pct_change'],\n",
    "    bins=[-np.inf, -0.10, 0.10, np.inf],\n",
    "    labels=['down', 'neutral', 'up']\n",
    ")\n",
    "\n",
    "print(\"\\n월별 등락률 예시:\")\n",
    "print(monthly_prices[['year_month','first','last','pct_change','category']].head())\n",
    "\n",
    "# ============================\n",
    "# 4) 병합 및 상위 단어 추출\n",
    "# ============================\n",
    "df_merged = pd.merge(\n",
    "    df_words,\n",
    "    monthly_prices[['year_month','category','pct_change']],\n",
    "    on='year_month',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 4-1) 카테고리별 단어 빈도 합계 → 상위 5개\n",
    "category_word_freq = (\n",
    "    df_merged\n",
    "    .groupby(['category','word'])['frequency']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "top_words_by_category = (\n",
    "    category_word_freq\n",
    "    .sort_values(['category','frequency'], ascending=[True, False])\n",
    "    .groupby('category')\n",
    "    .head(5)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\n=== 카테고리별 상위 5개 단어 (빈도 합계 기준) ===\")\n",
    "print(top_words_by_category.to_string(index=False))\n",
    "\n",
    "# ============================\n",
    "# 5) 단어 빈도와 등락률 상관계수 계산\n",
    "# ============================\n",
    "pivot_words = df_merged.pivot_table(\n",
    "    index='year_month',\n",
    "    columns='word',\n",
    "    values='frequency',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "corr_df = pd.merge(\n",
    "    pivot_words,\n",
    "    monthly_prices[['year_month','pct_change']],\n",
    "    on='year_month',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "word_columns = corr_df.columns.drop(['year_month','pct_change'])\n",
    "corr_series = corr_df[word_columns].corrwith(corr_df['pct_change']).sort_values(ascending=False)\n",
    "\n",
    "top_positive_corr = corr_series.head(5).reset_index()\n",
    "top_positive_corr.columns = ['단어','상관계수']\n",
    "top_negative_corr = corr_series.tail(5).reset_index()\n",
    "top_negative_corr.columns = ['단어','상관계수']\n",
    "\n",
    "print(\"\\n=== pct_change와 양(+) 상관 상위 5개 단어 ===\")\n",
    "print(top_positive_corr.round(4).to_string(index=False))\n",
    "\n",
    "print(\"\\n=== pct_change와 음(-) 상관 상위 5개 단어 ===\")\n",
    "print(top_negative_corr.round(4).to_string(index=False))\n",
    "\n",
    "# ============================\n",
    "# 6) CNN 모델 학습을 위한 데이터 준비\n",
    "# ============================\n",
    "X = corr_df[word_columns].values                   # (월 수, 단어 수)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))          # Conv1D 입력 형태: (samples, timesteps, channels)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(monthly_prices['category'])   # down→0, neutral→1, up→2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 7) 1D CNN 모델 정의 및 학습\n",
    "# ============================\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1],1)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== CNN 모델 학습 시작 ===\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[es],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 8) 모델 평가 및 결과 출력\n",
    "# ============================\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n=== 테스트 세트 평가 ===\\nLoss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 9) 모델링 기법 설명\n",
    "# ============================\n",
    "print(\"\\n=== 모델링 기법 설명 ===\")\n",
    "print(\n",
    "    \"이 스크립트에서는 '월별 단어 빈도 벡터'를 1차원 시계열처럼 보고,\\n\"\n",
    "    \"Conv1D(1D Convolutional Neural Network) 레이어를 통해 특징을 추출한 뒤\\n\"\n",
    "    \"GlobalMaxPooling1D → Dense → Softmax 구조로 'down', 'neutral', 'up' 세 클래스를 예측합니다.\\n\"\n",
    "    \"즉, 단어 빈도 패턴을 CNN이 학습하여 BTC 월별 등락 카테고리를 분류하는 모델링 방식입니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5827a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 1s - 217ms/step - accuracy: 0.3111 - loss: 6.5404 - val_accuracy: 0.1667 - val_loss: 11.5650\n",
      "Epoch 2/20\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.2889 - loss: 3.0049 - val_accuracy: 0.3333 - val_loss: 1.4696\n",
      "Epoch 3/20\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.3333 - loss: 2.5033 - val_accuracy: 0.5000 - val_loss: 1.3510\n",
      "Epoch 4/20\n",
      "6/6 - 0s - 20ms/step - accuracy: 0.3333 - loss: 1.4908 - val_accuracy: 0.1667 - val_loss: 3.7558\n",
      "Epoch 5/20\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.3778 - loss: 1.9378 - val_accuracy: 0.0000e+00 - val_loss: 3.5757\n",
      "Epoch 6/20\n",
      "6/6 - 0s - 20ms/step - accuracy: 0.3111 - loss: 1.5893 - val_accuracy: 0.1667 - val_loss: 1.7611\n",
      "==== 테스트 세트 평가: Loss=3.0187, Accuracy=0.3846 ====\n",
      "\n",
      "==== 연도별 월별 실제 카테고리 ====\n",
      "            01         02        03        04        05        06        07  \\\n",
      "year                                                                          \n",
      "2020   7200.85    9384.61   8531.88   6642.92   8826.96  10200.77   9232.00   \n",
      "2021  29331.69   33526.37  49587.03  58720.44  57800.37  36693.09  33504.69   \n",
      "2022  47722.65   38694.59  44421.20  46283.49  38468.35  29805.83  19279.80   \n",
      "2023  16616.75   23732.66  23628.97  28452.73  28068.26  26817.93  30585.90   \n",
      "2024  44179.55   43082.94  62387.90  69649.80  58364.97  67766.85  62899.99   \n",
      "2025  94591.79  100635.65  86064.53  85158.34       NaN       NaN       NaN   \n",
      "\n",
      "            08        09        10        11        12  \n",
      "year                                                    \n",
      "2020  11801.17  11921.97  10619.13  13761.50  18764.96  \n",
      "2021  39845.44  48810.52  48141.61  60911.11  57184.07  \n",
      "2022  23268.01  20131.46  19310.95  20483.62  16977.37  \n",
      "2023  29705.99  25805.05  27992.57  35421.43  38682.52  \n",
      "2024  65354.02  57301.86  60805.78  69496.01  97185.18  \n",
      "2025       NaN       NaN       NaN       NaN       NaN  \n",
      "\n",
      "==== 연도별 월별 예측 카테고리 ====\n",
      "        01    02    03    04    05    06    07    08    09    10    11    12\n",
      "year                                                                        \n",
      "2020  down  down  down  down  down    up  down    up  down  down  down  down\n",
      "2021  down    up  down  down  down  down  down  down  down  down  down  down\n",
      "2022  down  down  down  down    up  down  down  down  down  down  down  down\n",
      "2023  down  down  down  down  down    up    up  down  down  down  down  down\n",
      "2024  down  down  down  down  down  down  down  down  down  down  down  down\n",
      "2025    up  down  down  down   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "\n",
      "==== 연도별 월별 up_probability ====\n",
      "          01      02      03      04      05      06      07      08      09  \\\n",
      "year                                                                           \n",
      "2020  0.0938  0.0244  0.0663  0.1240  0.0207  0.5841  0.3953  0.6352  0.0141   \n",
      "2021  0.4424  1.0000  0.0018  0.0006  0.0203  0.0912  0.2888  0.0938  0.2828   \n",
      "2022  0.1605  0.4065  0.1684  0.2805  1.0000  0.2107  0.2789  0.2846  0.3398   \n",
      "2023  0.2948  0.2551  0.2113  0.2503  0.2933  0.4440  0.4790  0.3159  0.2661   \n",
      "2024  0.2813  0.4568  0.1654  0.3223  0.2827  0.1744  0.2363  0.1781  0.2336   \n",
      "2025  0.5368  0.1607  0.3578  0.3130     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "          10      11      12  \n",
      "year                          \n",
      "2020  0.1155  0.0457  0.0611  \n",
      "2021  0.0922  0.0562  0.3141  \n",
      "2022  0.3060  0.2691  0.3450  \n",
      "2023  0.3215  0.3218  0.2580  \n",
      "2024  0.3967  0.2796  0.1633  \n",
      "2025     NaN     NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================\n",
    "# 1) 파일 경로 지정\n",
    "# ============================\n",
    "# WORD_FILE  = './community/monthly_word_alt.csv'\n",
    "CHART_FILE = '../chart/BINANCE_BTCUSDT_daily_UTC.csv'\n",
    "\n",
    "# ============================\n",
    "# 2) 월별 단어 빈도 데이터 로드\n",
    "# ============================\n",
    "df_words = pd.read_csv(\n",
    "    WORD_FILE,\n",
    "    sep=',',\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "# 컬럼: ['month','count','rankw','word','frequency']\n",
    "# 'month'는 'YYYY-MM' 형식이라고 가정\n",
    "\n",
    "# ============================\n",
    "# 3) BTC 차트 데이터 로드 → 월별 등락률 계산\n",
    "# ============================\n",
    "df_chart = pd.read_csv(CHART_FILE, parse_dates=['date'])\n",
    "df_chart['year_month'] = df_chart['date'].dt.to_period('M')\n",
    "\n",
    "monthly_prices = (\n",
    "    df_chart\n",
    "    .groupby('year_month')['close']\n",
    "    .agg(first='first', last='last')\n",
    "    .reset_index()\n",
    ")\n",
    "monthly_prices['pct_change'] = (\n",
    "    monthly_prices['last'] - monthly_prices['first']\n",
    ") / monthly_prices['first']\n",
    "monthly_prices['year_month'] = monthly_prices['year_month'].dt.strftime('%Y-%m')\n",
    "monthly_prices['category'] = pd.cut(\n",
    "    monthly_prices['pct_change'],\n",
    "    bins=[-np.inf, -0.10, 0.10, np.inf],\n",
    "    labels=['down', 'neutral', 'up']\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 4) 월별 상위 10개 단어 추출\n",
    "# ============================\n",
    "df_words['year_month'] = df_words['month']\n",
    "top10_per_month = (\n",
    "    df_words\n",
    "    .sort_values(['month','frequency'], ascending=[True, False])\n",
    "    .groupby('month')\n",
    "    .head(10)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "months_sorted = sorted(df_words['month'].unique())\n",
    "\n",
    "# ============================\n",
    "# 5) CNN 입력 데이터 준비 (월별 상위 10개 단어 빈도)\n",
    "# ============================\n",
    "X_list = []\n",
    "for m in months_sorted:\n",
    "    subset = top10_per_month[top10_per_month['month'] == m]\n",
    "    freqs = subset['frequency'].tolist()\n",
    "    if len(freqs) < 10:\n",
    "        freqs += [0] * (10 - len(freqs))\n",
    "    X_list.append(freqs)\n",
    "X_arr = np.array(X_list, dtype=float)\n",
    "X = X_arr.reshape((X_arr.shape[0], X_arr.shape[1], 1))\n",
    "\n",
    "# y: 카테고리 인코딩\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(monthly_prices.set_index('year_month').loc[months_sorted, 'category'].values)\n",
    "\n",
    "# 학습/테스트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 6) 1D CNN 모델 정의 및 학습\n",
    "# ============================\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(10,1)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[es],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 7) 모델 평가 및 예측\n",
    "# ============================\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"==== 테스트 세트 평가: Loss={loss:.4f}, Accuracy={accuracy:.4f} ====\\n\")\n",
    "\n",
    "probabilities = model.predict(X, verbose=0)\n",
    "up_prob = probabilities[:, 2]  # “up” 클래스 확률\n",
    "pred_classes = np.argmax(probabilities, axis=1)\n",
    "predicted_labels = le.inverse_transform(pred_classes)\n",
    "\n",
    "# ============================\n",
    "# 8) 결과 정리\n",
    "# ============================\n",
    "results_df = pd.DataFrame({\n",
    "    'month':             months_sorted,\n",
    "    'actual_category':   monthly_prices.set_index('year_month').loc[months_sorted, 'category'].values,\n",
    "    'predicted_category': predicted_labels,\n",
    "    'up_probability':    up_prob.round(4),\n",
    "    'pct_change':        monthly_prices.set_index('year_month').loc[months_sorted, 'pct_change'].values\n",
    "})\n",
    "\n",
    "# ============================\n",
    "# 9) 연도·월 분리\n",
    "# ============================\n",
    "results_df[['year', 'month_num']] = results_df['month'].str.split('-', expand=True)\n",
    "results_df['year'] = results_df['year'].astype(int)\n",
    "results_df['month_num'] = results_df['month_num'].astype(int)\n",
    "\n",
    "# ============================\n",
    "# 10) 가로형 피벗: 각 필드를 연도별 1~12월 컬럼으로\n",
    "# ============================\n",
    "\n",
    "# ============================\n",
    "# 10-1) actual_price 피벗: 월별 종가(‘last’) 기준으로\n",
    "# ============================\n",
    "# 10-1-a) monthly_prices에서 'year', 'month_num', 'last' 컬럼 준비\n",
    "monthly_prices[['year', 'month_num']] = monthly_prices['year_month'].str.split('-', expand=True)\n",
    "monthly_prices['year'] = monthly_prices['year'].astype(int)\n",
    "monthly_prices['month_num'] = monthly_prices['month_num'].astype(int)\n",
    "\n",
    "# 10-1-b) 피벗 생성: index=year, columns=month_num, values=last (월말 종가)\n",
    "pivot_actual = (\n",
    "    monthly_prices\n",
    "    .pivot(index='year', columns='month_num', values='last')\n",
    ")\n",
    "pivot_actual.columns = [f\"{m:02d}\" for m in pivot_actual.columns]\n",
    "pivot_actual = pivot_actual.reindex(columns=[f\"{m:02d}\" for m in range(1, 13)])\n",
    "\n",
    "# 10-2) predicted_category 피벗\n",
    "pivot_pred = (\n",
    "    results_df\n",
    "    .pivot(index='year', columns='month_num', values='predicted_category')\n",
    ")\n",
    "pivot_pred.columns = [f\"{m:02d}\" for m in pivot_pred.columns]\n",
    "pivot_pred = pivot_pred.reindex(columns=[f\"{m:02d}\" for m in range(1, 13)])\n",
    "\n",
    "# 10-3) up_probability 피벗\n",
    "pivot_prob = (\n",
    "    results_df\n",
    "    .pivot(index='year', columns='month_num', values='up_probability')\n",
    ")\n",
    "pivot_prob.columns = [f\"{m:02d}\" for m in pivot_prob.columns]\n",
    "pivot_prob = pivot_prob.reindex(columns=[f\"{m:02d}\" for m in range(1, 13)])\n",
    "\n",
    "# ============================\n",
    "# 11) CSV로 저장\n",
    "# ============================\n",
    "pivot_actual.to_csv('./actual_category_by_year.csv', encoding='utf-8-sig')\n",
    "pivot_pred.to_csv('./predicted_category_by_year.csv', encoding='utf-8-sig')\n",
    "pivot_prob.to_csv('./up_probability_by_year.csv', encoding='utf-8-sig')\n",
    "\n",
    "# ============================\n",
    "# 12) 출력 확인\n",
    "# ============================\n",
    "print(\"==== 연도별 월별 실제 카테고리 ====\")\n",
    "print(pivot_actual)\n",
    "print(\"\\n==== 연도별 월별 예측 카테고리 ====\")\n",
    "print(pivot_pred)\n",
    "print(\"\\n==== 연도별 월별 up_probability ====\")\n",
    "print(pivot_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a6896",
   "metadata": {},
   "source": [
    "# 저장 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18426c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 2s - 297ms/step - accuracy: 0.2667 - loss: 5.5580 - val_accuracy: 0.1667 - val_loss: 9.7527\n",
      "Epoch 2/20\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.4000 - loss: 4.3630 - val_accuracy: 0.1667 - val_loss: 5.7708\n",
      "Epoch 3/20\n",
      "6/6 - 0s - 34ms/step - accuracy: 0.2444 - loss: 2.0718 - val_accuracy: 0.3333 - val_loss: 1.7476\n",
      "Epoch 4/20\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.2667 - loss: 2.0483 - val_accuracy: 0.6667 - val_loss: 1.0911\n",
      "Epoch 5/20\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.3556 - loss: 2.1844 - val_accuracy: 0.1667 - val_loss: 2.9816\n",
      "Epoch 6/20\n",
      "6/6 - 0s - 37ms/step - accuracy: 0.2889 - loss: 1.7096 - val_accuracy: 0.5000 - val_loss: 0.9310\n",
      "Epoch 7/20\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.2444 - loss: 1.7274 - val_accuracy: 0.5000 - val_loss: 1.3523\n",
      "Epoch 8/20\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.3778 - loss: 1.6314 - val_accuracy: 0.1667 - val_loss: 2.6197\n",
      "Epoch 9/20\n",
      "6/6 - 0s - 33ms/step - accuracy: 0.4000 - loss: 1.2401 - val_accuracy: 0.6667 - val_loss: 0.9810\n",
      "==== 테스트 세트 평가: Loss=1.5764, Accuracy=0.3077 ====\n",
      "\n",
      "==== 연도별 월별 실제 카테고리 ====\n",
      "            01         02        03        04        05        06        07  \\\n",
      "year                                                                          \n",
      "2020   7200.85    9384.61   8531.88   6642.92   8826.96  10200.77   9232.00   \n",
      "2021  29331.69   33526.37  49587.03  58720.44  57800.37  36693.09  33504.69   \n",
      "2022  47722.65   38694.59  44421.20  46283.49  38468.35  29805.83  19279.80   \n",
      "2023  16616.75   23732.66  23628.97  28452.73  28068.26  26817.93  30585.90   \n",
      "2024  44179.55   43082.94  62387.90  69649.80  58364.97  67766.85  62899.99   \n",
      "2025  94591.79  100635.65  86064.53  85158.34       NaN       NaN       NaN   \n",
      "\n",
      "            08        09        10        11        12  \n",
      "year                                                    \n",
      "2020  11801.17  11921.97  10619.13  13761.50  18764.96  \n",
      "2021  39845.44  48810.52  48141.61  60911.11  57184.07  \n",
      "2022  23268.01  20131.46  19310.95  20483.62  16977.37  \n",
      "2023  29705.99  25805.05  27992.57  35421.43  38682.52  \n",
      "2024  65354.02  57301.86  60805.78  69496.01  97185.18  \n",
      "2025       NaN       NaN       NaN       NaN       NaN  \n",
      "\n",
      "==== 연도별 월별 예측 카테고리 ====\n",
      "           01    02    03    04    05    06    07    08    09    10    11  \\\n",
      "year                                                                        \n",
      "2020     down  down  down  down  down    up  down  down  down  down  down   \n",
      "2021  neutral    up  down  down  down  down  down  down  down  down  down   \n",
      "2022     down  down  down  down    up  down  down  down  down  down  down   \n",
      "2023     down  down  down  down  down  down  down  down  down  down  down   \n",
      "2024     down  down  down  down  down  down  down  down  down  down  down   \n",
      "2025     down  down  down  down   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "        12  \n",
      "year        \n",
      "2020  down  \n",
      "2021  down  \n",
      "2022  down  \n",
      "2023  down  \n",
      "2024  down  \n",
      "2025   NaN  \n",
      "\n",
      "==== 연도별 월별 up_probability ====\n",
      "          01      02      03      04      05      06      07      08      09  \\\n",
      "year                                                                           \n",
      "2020  0.3221  0.1269  0.1923  0.2529  0.1575  0.7566  0.1720  0.0055  0.1996   \n",
      "2021  0.0464  0.9774  0.0484  0.0164  0.0668  0.1975  0.2294  0.2108  0.2700   \n",
      "2022  0.3385  0.2397  0.3250  0.3202  1.0000  0.2994  0.3240  0.3233  0.3219   \n",
      "2023  0.3258  0.3262  0.3528  0.3092  0.3292  0.2930  0.2910  0.2912  0.3215   \n",
      "2024  0.3174  0.2963  0.3047  0.2925  0.3140  0.3568  0.3931  0.3989  0.3249   \n",
      "2025  0.2445  0.2964  0.2907  0.3202     NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "          10      11      12  \n",
      "year                          \n",
      "2020  0.2929  0.0256  0.0718  \n",
      "2021  0.3124  0.3470  0.2851  \n",
      "2022  0.3119  0.3007  0.2664  \n",
      "2023  0.3645  0.2985  0.3093  \n",
      "2024  0.2844  0.2454  0.2585  \n",
      "2025     NaN     NaN     NaN  \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
