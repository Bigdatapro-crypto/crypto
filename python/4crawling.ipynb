{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d679dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "# --- Argument parsing ----------------------------------------------------------------\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--start-page', type=int, default=1, help='크롤링 시작 페이지')\n",
    "parser.add_argument('--end-page', type=int, default=200000, help='크롤링 종료 페이지')\n",
    "parser.add_argument('--total-posts', type=int, default=50000, help='샘플링할 게시물 수')\n",
    "parser.add_argument('--interval', type=int, default=120, help='샘플링 간격')\n",
    "parser.add_argument('--save-intv', type=int, default=10000, help='중간 저장 단위')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# --- 환경 설정 -----------------------------------------------------------------------\n",
    "start_page        = args.start_page\n",
    "end_page          = args.end_page\n",
    "TOTAL_POSTS       = args.total_posts\n",
    "SAMPLING_INTERVAL = args.interval\n",
    "SAVE_INTERVAL     = args.save_intv\n",
    "LIST_NUM          = 30  # 한 페이지당 게시물 수, 모바일은 js 동적이라 지정 불가능\n",
    "BASE_GALLERY      = \"bitcoins_new1\"\n",
    "# 모바일 도메인 사용\n",
    "BASE_LIST_URL     = f\"https://m.dcinside.com/board/{BASE_GALLERY}\"\n",
    "BASE_VIEW_URL     = f\"https://m.dcinside.com/board/{BASE_GALLERY}\"\n",
    "BASE_FILENAME     = 'dcinside_mobile'\n",
    "\n",
    "# 실행 환경 확인용\n",
    "print(f\"▶ BASE_LIST_URL: {BASE_LIST_URL}, BASE_VIEW_URL: {BASE_VIEW_URL}\")\n",
    "\n",
    "# 모바일 User-Agent 강제 지정\n",
    "MOBILE_UA = (\n",
    "    'Mozilla/5.0 (Linux; Android 10; SM-G970F) AppleWebKit/537.36 '\n",
    "    '(KHTML, like Gecko) Chrome/105.0.0.0 Mobile Safari/537.36'\n",
    ")\n",
    "\n",
    "def get_headers(referer=None):\n",
    "    headers = {'User-Agent': MOBILE_UA, 'Accept-Language': 'ko-KR,ko;q=0.9'}\n",
    "    if referer:\n",
    "        headers['Referer'] = referer\n",
    "    return headers\n",
    "\n",
    "# 상세페이지 정보 추출\n",
    "\n",
    "def extract_post_info(session, post_url):\n",
    "    resp = session.get(post_url, headers=get_headers(referer=post_url), timeout=(5, 30))\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "    # 본문 내용(모든 태그 포함)을 한 번에 가져와서 합치기\n",
    "    content_container = soup.select_one('div.gall-thum-btm div.thum-txt')\n",
    "    if content_container:\n",
    "        # 모든 하위 텍스트를 줄바꿈(sep='\\n')으로 합치고, 앞뒤 공백 제거\n",
    "        text = content_container.get_text(separator='\\n', strip=True)\n",
    "    else:\n",
    "        text = '내용 없음'\n",
    "        \n",
    "    view_elem  = soup.select_one('span.gall_count')\n",
    "    reply_elem = soup.select_one('span.gall_reply_num')\n",
    "\n",
    "    return {\n",
    "        '내용':       text,\n",
    "        '상세_조회수': re.sub(r'[^0-9]', '', view_elem.get_text()) if view_elem else '0',\n",
    "        '상세_댓글수': re.sub(r'[^0-9]', '', reply_elem.get_text()) if reply_elem else '0'\n",
    "    }\n",
    "    \n",
    "# CSV 저장\n",
    "\n",
    "def save_to_csv(df: pd.DataFrame, filename: str):\n",
    "    if not filename.endswith('.csv'):\n",
    "        filename = filename.rstrip('.parquet') + '.csv'\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] 저장 → {filename}\")\n",
    "\n",
    "# --- Main ----------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    session = requests.Session()\n",
    "    # 쿠키로 list_num 설정\n",
    "    session.cookies.set('list_num', str(LIST_NUM), domain='m.dcinside.com', path='/')\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    collected = []\n",
    "\n",
    "    # 샘플링 인덱스 생성\n",
    "    estimated_total = end_page * LIST_NUM\n",
    "    sample_indices = [i * SAMPLING_INTERVAL for i in range(1, TOTAL_POSTS + 1)\n",
    "                      if i * SAMPLING_INTERVAL <= estimated_total]\n",
    "\n",
    "    # 페이지별 오프셋 매핑\n",
    "    page_offsets = defaultdict(list)\n",
    "    for idx in sample_indices:\n",
    "        page = (idx - 1) // LIST_NUM + start_page\n",
    "        offset = (idx - 1) % LIST_NUM\n",
    "        page_offsets[page].append(offset)\n",
    "\n",
    "    part = 1\n",
    "    try:\n",
    "        # 프로그래스바를 총 샘플링할 게시물 수(TOTAL_POSTS)로 설정\n",
    "        pbar = tqdm(total=TOTAL_POSTS, desc=\"수집 진행\", unit=\"개\")\n",
    "        for page in range(start_page, end_page + 1):\n",
    "            offsets = page_offsets.get(page, [])\n",
    "            if not offsets:\n",
    "                continue\n",
    "            try:\n",
    "                resp = session.get(\n",
    "                    BASE_LIST_URL,\n",
    "                    params={'page': page},\n",
    "                    headers=get_headers(referer=BASE_LIST_URL),\n",
    "                    timeout=(5, 30)  # connect, read\n",
    "                )\n",
    "                resp.raise_for_status()\n",
    "            except requests.exceptions.ReadTimeout as e:\n",
    "                print(f\"[WARNING] 페이지 {page} 읽기 타임아웃: {e}. 2초 후 건너뜁니다.\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"[WARNING] 페이지 {page} 요청 실패: {e}. 건너뜁니다.\")\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "            # 모바일 리스트 항목 선택\n",
    "            items = soup.select('section:nth-of-type(3) ul.gall-detail-lst > li')\n",
    "            # print(f\"[DEBUG] page={page}, items found={len(items)}\")\n",
    "            if not items:\n",
    "                continue\n",
    "\n",
    "            # 리스트 메타 및 상세 수집\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "                futures = []\n",
    "                metas = []\n",
    "                for off in offsets:\n",
    "                    idx = min(off, len(items) - 1)\n",
    "                    item = items[idx]\n",
    "\n",
    "                    # 리스트 정보\n",
    "                    title   = item.select_one('a.lt span.subjectin')\n",
    "                    nick_li = item.select_one('a.lt ul li:nth-child(1)')\n",
    "                    date_li = item.select_one('a.lt ul li:nth-child(2)')\n",
    "                    views_li= item.select_one('a.lt ul li:nth-child(3)')\n",
    "                    reco_li = item.select_one('a.lt ul li:nth-child(4)')\n",
    "                    comm_li = item.select_one('a.rt > span')\n",
    "\n",
    "                    # href 및 post_id 추출 (쿼리 제거)\n",
    "                    link_tag = item.select_one('a.lt')\n",
    "                    if not link_tag:\n",
    "                        continue\n",
    "                    href = link_tag.get('href', '')\n",
    "                    parsed = urlparse(href)\n",
    "                    post_id = parsed.path.rstrip('/').split('/')[-1]\n",
    "                    post_url = href if href.startswith('http') else urljoin(BASE_VIEW_URL + '/', href)\n",
    "                    \n",
    "                    # 날짜 가공: “M.D” 형식일 때 뒤에 0 붙이기\n",
    "                    raw_date = date_li.get_text(strip=True) if date_li else ''\n",
    "                    if re.match(r'^\\d+\\.\\d$', raw_date):\n",
    "                        raw_date += '0'\n",
    "\n",
    "                    meta = {\n",
    "                        '글번호':      post_id,\n",
    "                        '제목':        title.get_text(strip=True) if title else '',\n",
    "                        '닉네임':      nick_li.get_text(strip=True) if nick_li else '',\n",
    "                        '날짜':        raw_date,\n",
    "                        '목록_조회수': re.sub(r'[^0-9]', '', views_li.get_text()) if views_li else '',\n",
    "                        '목록_추천수': re.sub(r'[^0-9]', '', reco_li.get_text())  if reco_li else '',\n",
    "                        '목록_댓글수': re.sub(r'[^0-9]', '', comm_li.get_text())  if comm_li else ''\n",
    "                    }\n",
    "                    metas.append(meta)\n",
    "                    futures.append(executor.submit(extract_post_info, session, post_url))\n",
    "\n",
    "                for meta, fut in zip(metas, futures):\n",
    "                    try:\n",
    "                        detail = fut.result(timeout=15)\n",
    "                        meta.update(detail)\n",
    "                        collected.append(meta)\n",
    "                        pbar.update(1)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            # 중간 저장\n",
    "            if len(collected) >= SAVE_INTERVAL:\n",
    "                final = f\"{BASE_FILENAME}_{timestamp}_{start_page}.csv\"\n",
    "                save_to_csv(pd.DataFrame(collected), final)\n",
    "                collected.clear()\n",
    "                part += 1\n",
    "\n",
    "            time.sleep(random.uniform(0.5, 1.0))\n",
    "            if len(collected) >= TOTAL_POSTS:\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('강제 종료, 저장 시도...')\n",
    "    finally:\n",
    "        pbar.close()\n",
    "        if collected:\n",
    "            final = f\"{BASE_FILENAME}_{timestamp}_{start_page}.csv\"\n",
    "            save_to_csv(pd.DataFrame(collected), final)\n",
    "        else:\n",
    "            print('저장할 데이터 없음.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
