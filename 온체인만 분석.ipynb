{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98672e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2706, 18)\n",
      "['Source.Name', 'Transaction Hash', 'Status', 'Type', 'Method', 'Block', 'Age', 'From', 'FromNameTag', 'To', 'ToNameTag', 'Amount', 'ValueUSD', 'Asset', 'TxnFee', 'Column1', 'Date', 'Timestamp']\n",
      "                                  Source.Name  \\\n",
      "0  export-advanced-filtered-1748689119705.csv   \n",
      "1  export-advanced-filtered-1748689119705.csv   \n",
      "2  export-advanced-filtered-1748689119705.csv   \n",
      "3  export-advanced-filtered-1748689119705.csv   \n",
      "4  export-advanced-filtered-1748689119705.csv   \n",
      "\n",
      "                                    Transaction Hash   Status    Type  \\\n",
      "0  0x6c97c0b2289cdf33911a55bab62fa2dbb358863b36b1...  Success  ERC-20   \n",
      "1  0xa95239e37762c1551b349d8149fdde55d40ab77ccdb7...  Success  ERC-20   \n",
      "2  0x06ace864d21fbd3ca6e7e6c47f7f1d1505522ce998c6...  Success  ERC-20   \n",
      "3  0xa34ee937e551677d41b1e7db3500f2e130a4a2ccfd55...  Success  ERC-20   \n",
      "4  0xb2f3f439837bd420661b3d55a6f6a88458e40fac7211...  Success  ERC-20   \n",
      "\n",
      "     Method     Block       Age         From  \\\n",
      "0  Transfer  Transfer  22385285  30 days ago   \n",
      "1  Transfer  Transfer  22385265  30 days ago   \n",
      "2  Transfer  Transfer  22384537  30 days ago   \n",
      "3    Supply    Supply  22384432  30 days ago   \n",
      "4  Transfer  Transfer  22384418  30 days ago   \n",
      "\n",
      "                                  FromNameTag        To  \\\n",
      "0  0x3b98B9e9Cb75C1cb1729Aab8f09Ced2936505E4f             \n",
      "1  0x7a93539c1bf9a96f87044925dEB7A0849266213E             \n",
      "2  0x9391466aD56F2705CE5fD12E763a65509aEE4862             \n",
      "3  0xEd0C6079229E2d407672a117c22b62064f4a4312             \n",
      "4  0x89e51fa8ca5d66cd220baed62ed01e8951aa7c40  Kraken 7   \n",
      "\n",
      "                                    ToNameTag                Amount  \\\n",
      "0  0x7a93539c1bf9a96f87044925dEB7A0849266213E                         \n",
      "1  0x3b98B9e9Cb75C1cb1729Aab8f09Ced2936505E4f                         \n",
      "2  0x92EA7496eba5F001d620005f88F3e8e686e3d4eA                         \n",
      "3  0x23878914efe38d27c4d67ab83ed1b93a74d4086a   Aave: Ethereum USDT   \n",
      "4  0xEd0C6079229E2d407672a117c22b62064f4a4312                         \n",
      "\n",
      "      ValueUSD            Asset            TxnFee   Column1        Date  \\\n",
      "0  85101470.13  $85,101,470.13   Tether USD(USDT)  0.000110  2025-03-31   \n",
      "1  92451975.00  $92,451,975.00   Tether USD(USDT)  0.000109  2025-03-31   \n",
      "2  62019335.52  $62,019,335.52   Tether USD(USDT)  0.000111  2025-03-31   \n",
      "3  30000000.00  $30,000,000.00   Tether USD(USDT)  0.000128  2025-03-31   \n",
      "4  47378580.33  $47,378,580.33   Tether USD(USDT)  0.000179  2025-03-31   \n",
      "\n",
      "    Timestamp  \n",
      "0  1743379200  \n",
      "1  1743379200  \n",
      "2  1743379200  \n",
      "3  1743379200  \n",
      "4  1743379200  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2706 entries, 0 to 2705\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Source.Name       2706 non-null   object \n",
      " 1   Transaction Hash  2706 non-null   object \n",
      " 2   Status            2706 non-null   object \n",
      " 3   Type              2706 non-null   object \n",
      " 4   Method            2706 non-null   object \n",
      " 5   Block             2706 non-null   object \n",
      " 6   Age               2706 non-null   int64  \n",
      " 7   From              2706 non-null   object \n",
      " 8   FromNameTag       2706 non-null   object \n",
      " 9   To                2706 non-null   object \n",
      " 10  ToNameTag         2706 non-null   object \n",
      " 11  Amount            2706 non-null   object \n",
      " 12  ValueUSD          2706 non-null   float64\n",
      " 13  Asset             2706 non-null   object \n",
      " 14  TxnFee            2706 non-null   object \n",
      " 15  Column1           2706 non-null   float64\n",
      " 16  Date              2706 non-null   object \n",
      " 17  Timestamp         2706 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 380.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 음수 기호 깨짐 방지\n",
    "\n",
    "# 1) 데이터 로드 및 컬럼명 앞뒤 공백 제거\n",
    "file_path = './onchain/usdt_onchain_250101_250430.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 2) 데이터 대략 살펴보기\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "print(df.head(5))\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47de7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ValueUSD\n",
      "count  2.706000e+03\n",
      "mean   7.707305e+07\n",
      "std    7.159732e+07\n",
      "min    3.000000e+07\n",
      "25%    4.000000e+07\n",
      "50%    6.000000e+07\n",
      "75%    9.081479e+07\n",
      "max    9.845025e+08\n"
     ]
    }
   ],
   "source": [
    "print(df[['Amount', 'ValueUSD', 'TxnFee']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3291bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status\n",
      "Success                          2694\n",
      "Error in Internal Transaction      12\n",
      "Name: count, dtype: int64\n",
      "Type\n",
      "ERC-20    2706\n",
      "Name: count, dtype: int64\n",
      "Method\n",
      "Transfer                           2347\n",
      "Supply                               99\n",
      "Withdraw                             67\n",
      "Transfer From                        61\n",
      "Borrow                               32\n",
      "Repay                                28\n",
      "Execute Transaction                  23\n",
      "Exec Transaction                     14\n",
      "Execute302                           13\n",
      "Finalize Withdrawal Transaction      12\n",
      "0x72276991                            4\n",
      "Execute                               3\n",
      "0xc5c2d919                            2\n",
      "Send                                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Status'].value_counts())\n",
    "print(df['Type'].value_counts())\n",
    "print(df['Method'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow\n",
    "# %pip install tensorflow\n",
    "# %pip install sklearn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "476e61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     --------------------------------------- 11.1/11.1 MB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\78831\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "     --------------------------------------- 41.3/41.3 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "     -------------------------------------- 307.7/307.7 kB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d343ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\78831\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.3)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 12.9/12.9 MB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\78831\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\78831\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\78831\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\78831\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\78831\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3723db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\78831\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\78831\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torch-2.7.0-cp310-cp310-win_amd64.whl (212.5 MB)\n",
      "     -------------------------------------- 212.5/212.5 MB 6.3 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "     -------------------------------------- 134.9/134.9 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\78831\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.13.2)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "     -------------------------------------- 199.1/199.1 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 8.5 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.0\n"
     ]
    }
   ],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f19f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1.1) CSV 읽기\n",
    "# (파일 경로를 실제 CSV 파일 이름/경로로 바꿔주세요)\n",
    "df = pd.read_csv(\"onchain/usdt_onchain_250101_250430.csv\")\n",
    "\n",
    "# 1.2) CSV 헤더 예시\n",
    "# 컬럼: ['Source.Name','Transaction Hash','Status','Type','Method',\n",
    "#       'Block','Age','From','FromNameTag','To','ToNameTag',\n",
    "#       'Amount','ValueUSD','Asset','TxnFee','Column1','Date','Timestamp']\n",
    "\n",
    "# 1.3) 관심 없는 컬럼(drop) – 예시\n",
    "cols_to_drop = [\n",
    "    \"Source.Name\", \"Transaction Hash\", \"Status\", \"Method\",\n",
    "    \"FromNameTag\", \"ToNameTag\", \"Column1\"\n",
    "]\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fe63855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) CSV 읽기\n",
    "df = pd.read_csv(\"onchain/usdt_onchain_250101_250430.csv\")\n",
    "\n",
    "# 2) 필요 없는 컬럼 제거 (예시)\n",
    "cols_to_drop = [\"Source.Name\", \"Transaction Hash\", \"Status\", \"Method\",\n",
    "                \"FromNameTag\", \"ToNameTag\", \"Column1\"]\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# 3) Amount, ValueUSD, TxnFee → 숫자형으로 변환 (오류 시 NaN 처리)\n",
    "df[\"Amount\"] = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\n",
    "df[\"ValueUSD\"] = (\n",
    "    df[\"ValueUSD\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r'[$,]', \"\", regex=True)\n",
    ")\n",
    "df[\"ValueUSD\"] = pd.to_numeric(df[\"ValueUSD\"], errors=\"coerce\")\n",
    "df[\"TxnFee\"] = pd.to_numeric(df[\"TxnFee\"], errors=\"coerce\")\n",
    "\n",
    "# 4) 날짜(Date) → datetime으로 변환\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "# 5) 변환 과정에서 생긴 NaN 행 삭제\n",
    "df = df.dropna(subset=[\"Amount\", \"ValueUSD\", \"TxnFee\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# 6) 인덱스를 Date로 설정\n",
    "df = df.set_index(\"Date\").sort_index()\n",
    "\n",
    "# --- 이후에는 앞서 안내드린 대로 일별 집계(예: resample) 및 라벨 생성 과정을 이어가시면 됩니다. ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da8971a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\78831\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTxnFee\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTxnFee\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Date 열을 datetime으로 변환 (형식: \"2025-03-31\")\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Timestamp가 Unix epoch(초)라면, 아래처럼 대체 가능\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# df[\"Timestamp\"] = pd.to_numeric(df[\"Timestamp\"], errors=\"coerce\")\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# df[\"Date\"] = pd.to_datetime(df[\"Timestamp\"], unit=\"s\", errors=\"coerce\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 변환 과정에서 Amount·ValueUSD·TxnFee·Date 중 하나라도 NaN인 행들을 모두 제거\u001b[39;00m\n\u001b[0;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValueUSD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTxnFee\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\78831\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\78831\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "# Amount, ValueUSD, TxnFee 열을 숫자형으로 변환 (오류 시 NaN 처리)\n",
    "df[\"Amount\"] = pd.to_numeric(df[\"Amount\"], errors=\"coerce\")\n",
    "\n",
    "# ValueUSD에 \"$\"나 쉼표가 끼어있는 경우를 대비해 먼저 문자열로 바꾼 뒤 정규표현식으로 제거\n",
    "df[\"ValueUSD\"] = (\n",
    "    df[\"ValueUSD\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r'[$,]', \"\", regex=True)\n",
    ")\n",
    "df[\"ValueUSD\"] = pd.to_numeric(df[\"ValueUSD\"], errors=\"coerce\")\n",
    "\n",
    "df[\"TxnFee\"] = pd.to_numeric(df[\"TxnFee\"], errors=\"coerce\")\n",
    "\n",
    "# Date 열을 datetime으로 변환 (형식: \"2025-03-31\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "# Timestamp가 Unix epoch(초)라면, 아래처럼 대체 가능\n",
    "# df[\"Timestamp\"] = pd.to_numeric(df[\"Timestamp\"], errors=\"coerce\")\n",
    "# df[\"Date\"] = pd.to_datetime(df[\"Timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "# 변환 과정에서 Amount·ValueUSD·TxnFee·Date 중 하나라도 NaN인 행들을 모두 제거\n",
    "df = df.dropna(subset=[\"Amount\", \"ValueUSD\", \"TxnFee\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# Date를 인덱스로 설정\n",
    "df = df.set_index(\"Date\").sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65ed22ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== daily_features 상위 5개 ===\n",
      "Empty DataFrame\n",
      "Columns: [Amount, ValueUSD, TxnFee, TxCount, AvgTxnValueUSD, UniqueSenders, TransferRate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Block 컬럼을 거래 건수(Count)로 사용\n",
    "daily = df.resample(\"D\").agg({\n",
    "    \"Amount\":   \"sum\",   # 하루 총 Amount 합계\n",
    "    \"ValueUSD\": \"sum\",   # 하루 총 USD 합계\n",
    "    \"TxnFee\":   \"sum\",   # 하루 총 TxnFee 합계\n",
    "    \"Block\":    \"count\"  # 하루 거래 건수 (Block 값의 개수)\n",
    "})\n",
    "daily = daily.rename(columns={\"Block\": \"TxCount\"})\n",
    "\n",
    "# 평균 거래액 = 하루 총 ValueUSD / 거래 건수\n",
    "daily[\"AvgTxnValueUSD\"] = daily[\"ValueUSD\"] / daily[\"TxCount\"]\n",
    "\n",
    "# 고유 보낸 주소 개수(일별 UniqueSenders)\n",
    "daily[\"UniqueSenders\"] = df.groupby(pd.Grouper(freq=\"D\"))[\"From\"].nunique()\n",
    "\n",
    "# Type이 \"Transfer\"/\"Supply\" 두 가지가 모두 있는 경우, Transfer 비율 계산\n",
    "type_counts = df.groupby([pd.Grouper(freq=\"D\"), \"Type\"]).size().unstack(fill_value=0)\n",
    "if \"Transfer\" in type_counts.columns and \"Supply\" in type_counts.columns:\n",
    "    type_counts[\"TransferRate\"] = (\n",
    "        type_counts[\"Transfer\"] / (type_counts[\"Transfer\"] + type_counts[\"Supply\"])\n",
    "    )\n",
    "    type_counts = type_counts[[\"TransferRate\"]]\n",
    "else:\n",
    "    # 만약 둘 중 하나라도 없으면 0으로 채워두기\n",
    "    type_counts[\"TransferRate\"] = 0.0\n",
    "    type_counts = type_counts[[\"TransferRate\"]]\n",
    "\n",
    "# 최종 일별 피처 DataFrame\n",
    "daily_features = daily.join(type_counts, how=\"left\").fillna(0)\n",
    "\n",
    "print(\"=== daily_features 상위 5개 ===\")\n",
    "print(daily_features.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
